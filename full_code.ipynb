import pandas as pd
import numpy as np
import yfinance as yf
from fredapi import Fred
from google.colab import userdata
from sklearn.linear_model import Ridge
from sklearn.model_selection import TimeSeriesSplit
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

def get_fred_api():
    return Fred(api_key=userdata.get("FRED_API_KEY"))

def fetch_macro_data(fred):
    series = {
        "cpi": "CPIAUCSL",
        "fed_funds": "FEDFUNDS",
        "unemployment": "UNRATE",
        "yield_spread": "T10Y2Y",
        "industrial_production": "INDPRO"
    }
    macro = pd.DataFrame({name: fred.get_series(code) for name, code in series.items()})
    macro.index = pd.to_datetime(macro.index)
    macro_m = pd.DataFrame(index=macro.resample("ME").mean().index)
    macro_m["cpi"] = macro["cpi"].resample("ME").last()
    macro_m["fed_funds"] = macro["fed_funds"].resample("ME").last()
    macro_m["unemployment"] = macro["unemployment"].resample("ME").last()
    macro_m["industrial_production"] = macro["industrial_production"].resample("ME").last()
    macro_m["yield_spread"] = macro["yield_spread"].resample("ME").mean()
    return macro_m.loc["2000-01-31":].dropna()

def fetch_sector_returns():
    tickers = ["XLF","XLK","XLV","XLY","XLP","XLE","XLI","XLB","XLU","XLRE","XLC"]
    prices = yf.download(tickers, start="2000-01-01", auto_adjust=True)["Close"]
    monthly_prices = prices.resample("ME").last()
    returns = np.log(monthly_prices / monthly_prices.shift(1))
    return returns.dropna(how="all")

def create_macro_features(macro_df):
    features = pd.DataFrame(index=macro_df.index)
    features["cpi_yoy"] = macro_df["cpi"].pct_change(12)
    features["fed_funds_change"] = macro_df["fed_funds"].diff()
    features["unemployment_change"] = macro_df["unemployment"].diff()
    features["yield_spread"] = macro_df["yield_spread"]
    features["industrial_prod_yoy"] = macro_df["industrial_production"].pct_change(12)
    return features.dropna()

def add_lags(df, lags=[1, 3, 6, 12]):
    parts = [df]
    for lag in lags:
        shifted = df.shift(lag)
        shifted.columns = [f"{col}_lag{lag}" for col in df.columns]
        parts.append(shifted)
    return pd.concat(parts, axis=1).dropna()

def ts_cv_r2(X, y, alpha=10.0, splits=5):
    tscv = TimeSeriesSplit(n_splits=splits)
    scores = []
    model = Ridge(alpha=alpha)
    for train_idx, test_idx in tscv.split(X):
        model.fit(X.iloc[train_idx], y.iloc[train_idx])
        scores.append(model.score(X.iloc[test_idx], y.iloc[test_idx]))
    return float(np.mean(scores))

def train_ridge_models(dataset, feature_cols, alpha=10.0):
    results = []
    coefficients = {}
    models = {}
    for sector in sorted(dataset["sector"].unique()):
        df = dataset[dataset["sector"] == sector].sort_values("Date")
        X = df[feature_cols]
        y = df["return"]
        cv_r2 = ts_cv_r2(X, y, alpha)
        pipe = Pipeline([("scaler", StandardScaler()), ("ridge", Ridge(alpha=alpha))])
        pipe.fit(X, y)
        models[sector] = pipe
        coefs = pd.Series(pipe.named_steps["ridge"].coef_, index=feature_cols)
        coefficients[sector] = coefs.sort_values(key=np.abs, ascending=False)
        results.append({"sector": sector, "observations": len(df), "cv_r2": cv_r2})
    return pd.DataFrame(results).sort_values("cv_r2", ascending=False), coefficients, models

def make_scenario(base: pd.DataFrame, name: str):
    sc = base.copy()
    sc.attrs["name"] = name
    return sc

def define_scenarios(baseline_path):
    rate_shock = make_scenario(baseline_path, "Rate Shock")
    rate_shock.loc[rate_shock.index[:6], "fed_funds_change"] += 1.00 / 6
    recession = make_scenario(baseline_path, "Recession")
    recession["unemployment_change"] += 0.10
    recession["industrial_prod_yoy"] += -0.02
    recession["yield_spread"] += -0.75
    stagflation = make_scenario(baseline_path, "Stagflation")
    stagflation["cpi_yoy"] += 0.02
    stagflation["industrial_prod_yoy"] += -0.015
    stagflation["yield_spread"] += -0.25
    return rate_shock, recession, stagflation

def build_lagged_from_history_and_future(history: pd.DataFrame, future: pd.DataFrame, lags=[1, 3, 6, 12]):
    full = pd.concat([history, future], axis=0)
    parts = [full]
    for lag in lags:
        shifted = full.shift(lag)
        shifted.columns = [f"{c}_lag{lag}" for c in full.columns]
        parts.append(shifted)
    full_lagged = pd.concat(parts, axis=1)
    return full_lagged.loc[future.index].dropna()

def predict_scenario_returns(models, macro_history, scenario_df, feature_cols):
    X_future = build_lagged_from_history_and_future(macro_history, scenario_df)
    X_future = X_future[feature_cols]
    preds = pd.DataFrame(index=X_future.index)
    for sector, model in models.items():
        preds[sector] = model.predict(X_future)
    return preds

def summarize(pred: pd.DataFrame, name: str):
    cum_log = pred.sum(axis=0)
    cum_simple = np.exp(cum_log) - 1
    return pd.DataFrame({"scenario": name, "cum_12m_return": cum_simple}).sort_values("cum_12m_return")

def portfolio_path(pred: pd.DataFrame, weights: pd.Series):
    w = weights.reindex(pred.columns).fillna(0)
    port_log = pred.mul(w, axis=1).sum(axis=1)
    return np.exp(port_log.cumsum()) - 1

def sector_12m_returns(pred_df):
    cum_log = pred_df.sum(axis=0)
    cum_simple = np.exp(cum_log) - 1
    return cum_simple.sort_values()

def plot_portfolio_paths(paths: dict):
    plt.figure()
    for name, series in paths.items():
        plt.plot(series.index, series.values, label=name)
    plt.axhline(0, linewidth=1)
    plt.title("Portfolio Cumulative Return Under Scenarios")
    plt.xlabel("Date")
    plt.ylabel("Cumulative Return")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

def plot_sector_bars(sector_returns, title):
    plt.figure(figsize=(9, 4))
    plt.bar(sector_returns.index, sector_returns.values)
    plt.axhline(0, linewidth=1)
    plt.title(title)
    plt
